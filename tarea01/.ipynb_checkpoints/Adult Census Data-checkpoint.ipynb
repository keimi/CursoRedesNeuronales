{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Tarea 1 de Redes Neuronales #\n",
    "\n",
    "## Tests unitarios ##\n",
    "\n",
    "Para correr los test de la tarea se ejecuta el siguiente codigo estando en la carpeta de la tarea:\n",
    "\n",
    "```\n",
    "python test_network.py\n",
    "```\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "## Dataset de censo para adultos ##\n",
    "\n",
    "Se probara la tarea utilizando un dataset con campos recolectados de varios censos en el mundo que trata de adivinar si el sueldo de una persona supera los 50 mil dolares el a√±o"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style>\n",
       "    .dataframe thead tr:only-child th {\n",
       "        text-align: right;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: left;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>age</th>\n",
       "      <th>workclass</th>\n",
       "      <th>fnlwgt</th>\n",
       "      <th>education</th>\n",
       "      <th>education-num</th>\n",
       "      <th>marital-status</th>\n",
       "      <th>occupation</th>\n",
       "      <th>relationship</th>\n",
       "      <th>race</th>\n",
       "      <th>sex</th>\n",
       "      <th>capital-gain</th>\n",
       "      <th>capital-loss</th>\n",
       "      <th>hours-per-week</th>\n",
       "      <th>native-country</th>\n",
       "      <th>target</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>39</td>\n",
       "      <td>State-gov</td>\n",
       "      <td>77516</td>\n",
       "      <td>Bachelors</td>\n",
       "      <td>13</td>\n",
       "      <td>Never-married</td>\n",
       "      <td>Adm-clerical</td>\n",
       "      <td>Not-in-family</td>\n",
       "      <td>White</td>\n",
       "      <td>Male</td>\n",
       "      <td>2174</td>\n",
       "      <td>0</td>\n",
       "      <td>40</td>\n",
       "      <td>United-States</td>\n",
       "      <td>&lt;=50K</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>50</td>\n",
       "      <td>Self-emp-not-inc</td>\n",
       "      <td>83311</td>\n",
       "      <td>Bachelors</td>\n",
       "      <td>13</td>\n",
       "      <td>Married-civ-spouse</td>\n",
       "      <td>Exec-managerial</td>\n",
       "      <td>Husband</td>\n",
       "      <td>White</td>\n",
       "      <td>Male</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>13</td>\n",
       "      <td>United-States</td>\n",
       "      <td>&lt;=50K</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>38</td>\n",
       "      <td>Private</td>\n",
       "      <td>215646</td>\n",
       "      <td>HS-grad</td>\n",
       "      <td>9</td>\n",
       "      <td>Divorced</td>\n",
       "      <td>Handlers-cleaners</td>\n",
       "      <td>Not-in-family</td>\n",
       "      <td>White</td>\n",
       "      <td>Male</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>40</td>\n",
       "      <td>United-States</td>\n",
       "      <td>&lt;=50K</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>53</td>\n",
       "      <td>Private</td>\n",
       "      <td>234721</td>\n",
       "      <td>11th</td>\n",
       "      <td>7</td>\n",
       "      <td>Married-civ-spouse</td>\n",
       "      <td>Handlers-cleaners</td>\n",
       "      <td>Husband</td>\n",
       "      <td>Black</td>\n",
       "      <td>Male</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>40</td>\n",
       "      <td>United-States</td>\n",
       "      <td>&lt;=50K</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>28</td>\n",
       "      <td>Private</td>\n",
       "      <td>338409</td>\n",
       "      <td>Bachelors</td>\n",
       "      <td>13</td>\n",
       "      <td>Married-civ-spouse</td>\n",
       "      <td>Prof-specialty</td>\n",
       "      <td>Wife</td>\n",
       "      <td>Black</td>\n",
       "      <td>Female</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>40</td>\n",
       "      <td>Cuba</td>\n",
       "      <td>&lt;=50K</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   age         workclass  fnlwgt  education  education-num  \\\n",
       "0   39         State-gov   77516  Bachelors             13   \n",
       "1   50  Self-emp-not-inc   83311  Bachelors             13   \n",
       "2   38           Private  215646    HS-grad              9   \n",
       "3   53           Private  234721       11th              7   \n",
       "4   28           Private  338409  Bachelors             13   \n",
       "\n",
       "       marital-status         occupation   relationship   race     sex  \\\n",
       "0       Never-married       Adm-clerical  Not-in-family  White    Male   \n",
       "1  Married-civ-spouse    Exec-managerial        Husband  White    Male   \n",
       "2            Divorced  Handlers-cleaners  Not-in-family  White    Male   \n",
       "3  Married-civ-spouse  Handlers-cleaners        Husband  Black    Male   \n",
       "4  Married-civ-spouse     Prof-specialty           Wife  Black  Female   \n",
       "\n",
       "   capital-gain  capital-loss  hours-per-week native-country target  \n",
       "0          2174             0              40  United-States  <=50K  \n",
       "1             0             0              13  United-States  <=50K  \n",
       "2             0             0              40  United-States  <=50K  \n",
       "3             0             0              40  United-States  <=50K  \n",
       "4             0             0              40           Cuba  <=50K  "
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn import preprocessing\n",
    "\n",
    "adult_data = pd.read_csv('./data/adult.data')\n",
    "adult_data.head(5)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Se debe convertir la data a numeros entre 0.0 y 1.0 para poder utilizarla en la red neuronal"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "dics = []\n",
    "maxN = []\n",
    "for idcol, col in enumerate(adult_data.columns):\n",
    "    dic = {}\n",
    "    if adult_data.dtypes[idcol] == np.dtype('O'):\n",
    "        ro = np.unique([str(x) for x in adult_data[col].values])\n",
    "        for i, val in enumerate(ro):\n",
    "            dic[val] = i\n",
    "        maxN.append(ro.size)\n",
    "    else:\n",
    "        maxN.append(0)\n",
    "        \n",
    "    dics.append(dic)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[39, 7, 77516, ..., 40, 39, 0],\n",
       "       [50, 6, 83311, ..., 13, 39, 0],\n",
       "       [38, 4, 215646, ..., 40, 39, 0],\n",
       "       ..., \n",
       "       [58, 4, 151910, ..., 40, 39, 0],\n",
       "       [22, 4, 201490, ..., 20, 39, 0],\n",
       "       [52, 5, 287927, ..., 40, 39, 1]], dtype=object)"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "M = adult_data.values\n",
    "for i, arr in enumerate(M):\n",
    "    for j, val in enumerate(arr):\n",
    "        if val.__class__ == ' '.__class__:\n",
    "            M[i][j] = dics[j][M[i][j]]\n",
    "            \n",
    "M"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/kaminari/anaconda3/lib/python3.6/site-packages/sklearn/utils/validation.py:429: DataConversionWarning: Data with input dtype object was converted to float64 by MinMaxScaler.\n",
      "  warnings.warn(msg, _DataConversionWarning)\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "array([[ 0.30136986,  0.875     ,  0.0443019 , ...,  0.39795918,\n",
       "         0.95121951,  0.        ],\n",
       "       [ 0.45205479,  0.75      ,  0.0482376 , ...,  0.12244898,\n",
       "         0.95121951,  0.        ],\n",
       "       [ 0.28767123,  0.5       ,  0.13811345, ...,  0.39795918,\n",
       "         0.95121951,  0.        ],\n",
       "       ..., \n",
       "       [ 0.56164384,  0.5       ,  0.09482688, ...,  0.39795918,\n",
       "         0.95121951,  0.        ],\n",
       "       [ 0.06849315,  0.5       ,  0.12849934, ...,  0.19387755,\n",
       "         0.95121951,  0.        ],\n",
       "       [ 0.47945205,  0.625     ,  0.18720338, ...,  0.39795918,\n",
       "         0.95121951,  1.        ]])"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "min_max_scaler = preprocessing.MinMaxScaler()\n",
    "M_scaled = min_max_scaler.fit_transform(np.array(M))\n",
    "M_scaled"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Con la data convertida a numero se procede a crear la red y entrenarla con 30000 datos"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# train network\n",
    "from neuron_network import NeuronNetwork\n",
    "\n",
    "network = NeuronNetwork(14, 0.5)\n",
    "network.add_layer(100)\n",
    "network.add_layer(50)\n",
    "network.add_layer(10)\n",
    "network.add_layer(20)\n",
    "network.add_layer(1)\n",
    "\n",
    "for tr in range(30000):\n",
    "    expected = M_scaled[tr][14]\n",
    "\n",
    "    inputs = np.array(M_scaled[tr][0:14])\n",
    "    output = network.feed(inputs)[0]\n",
    "    network.backpropagate_error(expected)\n",
    "    network.update_weights()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "y se ocupan un poco mas de 2500 datos para probar el resultado"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 210,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "prec:  0.7629233511586453 error:  0.303098475234\n"
     ]
    }
   ],
   "source": [
    "sumTrue = 0\n",
    "errors = np.array([])\n",
    "for i in range(32000,32561):\n",
    "    inputs = np.array(M_scaled[i][0:14])\n",
    "    output = network.feed(inputs)\n",
    "\n",
    "    raw_output = network.feed(inputs)[0]\n",
    "    output = 1.0 if raw_output > 0.5 else 0.0\n",
    "    expected = M_scaled[i][14]\n",
    "\n",
    "    errors = np.append(errors, expected - raw_output)\n",
    "#     print(output, expected)\n",
    "    if output == expected:\n",
    "        sumTrue += 1\n",
    "        \n",
    "#     if expected == 1:\n",
    "#         print(i)\n",
    "\n",
    "precision = sumTrue / (32561-32000)\n",
    "promError = np.mean(np.abs(errors))\n",
    "print('prec: ', str(precision), 'error: ', str(promError))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Los resultados de precisi√≥n y error medio se muestran arriba. Estos resultados no son tan buenos, pero se espera mejorar agregando capas intermedias."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "# Preguntas #\n",
    "\n",
    "## How does the number of hidden layers impact the learning rate? ##\n",
    "\n",
    "A medida que que se tienen mas capas la red se hace mas especifica para un grupo de inputs. Mas capas debiera significar que la red se especifica mejor en el entrenamiento, pero se demorara mas en entrenar.\n",
    "\n",
    "## What is the speed of your network to process data ? ##\n",
    "\n",
    "Depende del n√∫mero de hidden layers, con la red que se presenta se demora alrededor de 3 minutos en entrenar 30000 datos.\n",
    "\n",
    "## Effect of different learning rates ##\n",
    "\n",
    "En los test (AND, OR, XOR) se pudo ratificar que en general se llegaba m√°s r√°pido a la convergencia con learning rates altos (alrededor de 0.5), con learning rates bajos se demoraba mucho en llegar a la convergencia.\n",
    "\n",
    "## Does the order of the training data matter? ##\n",
    "\n",
    "Si importa, si se entrena mucho tiempo solo con data de un tipo, la red adquiere cierta arquitectura (preferencia por algun dato) que luego cuesta cambiar.\n",
    "\n",
    "## What are the neurons that changes the most during the learning ##\n",
    "\n",
    "Las neuronas que m√°s cambian son las mas cercanas a la salida. Las de mas atras cambian menos.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
